{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Get My Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "data_all = np.load('50kdataNegZ.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadrotorDataset(Dataset):\n",
    "  def __init__(self, data_path = 'testing.csv', time_size=1, state_size = 9, ctrlinput_size = 4, training=True, data_all = data_all):\n",
    "    self.input_size = state_size + ctrlinput_size\n",
    "    self.output_size = ctrlinput_size\n",
    "\n",
    "    self.data = data_all\n",
    "\n",
    "    np.random.shuffle(data_all)\n",
    "    train_size = int(len(data_all)*0.8)\n",
    "\n",
    "\n",
    "    if training:\n",
    "      self.data = data_all[0:train_size]\n",
    "    else:\n",
    "      self.data = data_all[train_size:]\n",
    "\n",
    "    print(self.data.shape)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    # print(self.data[idx,:])\n",
    "    inputs = self.data[idx, 0: self.input_size]\n",
    "    outputs = self.data[idx, self.input_size:]\n",
    "    # print(type(inputs))\n",
    "    # print(type(outputs))\n",
    "    # print(inputs)\n",
    "    # print(inputs.dtype)\n",
    "    # print(\"h\")\n",
    "    return torch.FloatTensor(inputs), torch.FloatTensor(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 17)\n",
      "(10000, 17)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = QuadrotorDataset(training=True)\n",
    "test_dataset = QuadrotorDataset(training=False)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.2796,  0.2250, -0.9266, -0.2119,  0.3931,  0.0851,  0.1105, -0.1578,\n",
       "          0.0582,  8.6734, -0.8850, -0.7833,  0.0305]),\n",
       " tensor([-0.0220,  0.4759,  0.5814,  0.0826]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary Files for Building and Training INN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.autograd import Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MonSingleFC and MONReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MONSingleFc(nn.Module):\n",
    "    \"\"\" Simple MON linear class, just a single full multiply. \"\"\"\n",
    "\n",
    "    def __init__(self, in_dim, out_dim, m=1.0):\n",
    "        super().__init__()\n",
    "        self.U = nn.Linear(in_dim, out_dim)\n",
    "        self.A = nn.Linear(out_dim, out_dim, bias=False)\n",
    "        self.B = nn.Linear(out_dim, out_dim, bias=False)\n",
    "        self.m = m\n",
    "\n",
    "    def x_shape(self, n_batch):\n",
    "        return (n_batch, self.U.in_features)\n",
    "\n",
    "    def z_shape(self, n_batch):\n",
    "        return ((n_batch, self.A.in_features),)\n",
    "\n",
    "    def forward(self, x, *z):\n",
    "        return (self.U(x) + self.multiply(*z)[0],)\n",
    "\n",
    "    def bias(self, x):\n",
    "        return (self.U(x),)\n",
    "\n",
    "    def multiply(self, *z):\n",
    "        ATAz = self.A(z[0]) @ self.A.weight\n",
    "        z_out = (1 - self.m) * z[0] - ATAz + self.B(z[0]) - z[0] @ self.B.weight\n",
    "        return (z_out,)\n",
    "\n",
    "    def multiply_transpose(self, *g):\n",
    "        ATAg = self.A(g[0]) @ self.A.weight\n",
    "        g_out = (1 - self.m) * g[0] - ATAg - self.B(g[0]) + g[0] @ self.B.weight\n",
    "        return (g_out,)\n",
    "\n",
    "    def init_inverse(self, alpha, beta):\n",
    "        I = torch.eye(self.A.weight.shape[0], dtype=self.A.weight.dtype,\n",
    "                      device=self.A.weight.device)\n",
    "        W = (1 - self.m) * I - self.A.weight.T @ self.A.weight + self.B.weight - self.B.weight.T\n",
    "        self.Winv = torch.inverse(alpha * I + beta * W)\n",
    "\n",
    "    def inverse(self, *z):\n",
    "        return (z[0] @ self.Winv.transpose(0, 1),)\n",
    "\n",
    "    def inverse_transpose(self, *g):\n",
    "        return (g[0] @ self.Winv,)\n",
    "\n",
    "\n",
    "class MONReLU(nn.Module):\n",
    "    def forward(self, *z):\n",
    "        return tuple(F.relu(z_) for z_ in z)\n",
    "\n",
    "    def derivative(self, *z):\n",
    "        return tuple((z_ > 0).type_as(z[0]) for z_ in z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Meter(object):\n",
    "    \"\"\"Computes and stores the min, max, avg, and current values\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        self.max = -float(\"inf\")\n",
    "        self.min = float(\"inf\")\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        self.max = max(self.max, val)\n",
    "        self.min = min(self.min, val)\n",
    "\n",
    "\n",
    "class SplittingMethodStats(object):\n",
    "    def __init__(self):\n",
    "        self.fwd_iters = Meter()\n",
    "        self.bkwd_iters = Meter()\n",
    "        self.fwd_time = Meter()\n",
    "        self.bkwd_time = Meter()\n",
    "\n",
    "    def reset(self):\n",
    "        self.fwd_iters.reset()\n",
    "        self.fwd_time.reset()\n",
    "        self.bkwd_iters.reset()\n",
    "        self.bkwd_time.reset()\n",
    "\n",
    "    def report(self):\n",
    "        print('Fwd iters: {:.2f}\\tFwd Time: {:.4f}\\tBkwd Iters: {:.2f}\\tBkwd Time: {:.4f}\\n'.format(\n",
    "                self.fwd_iters.avg, self.fwd_time.avg,\n",
    "                self.bkwd_iters.avg, self.bkwd_time.avg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Splitting Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MONPeacemanRachford(nn.Module):\n",
    "\n",
    "    def __init__(self, linear_module, nonlin_module, alpha=1.0, tol=1e-5, max_iter=50, verbose=False):\n",
    "        super().__init__()\n",
    "        self.linear_module = linear_module\n",
    "        self.nonlin_module = nonlin_module\n",
    "        self.alpha = alpha\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.verbose = verbose\n",
    "        self.stats = SplittingMethodStats()\n",
    "        self.save_abs_err = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" Forward pass of the MON, find an equilibirum with forward-backward splitting\"\"\"\n",
    "\n",
    "        start = time.time()\n",
    "        # Run the forward pass _without_ tracking gradients\n",
    "        self.linear_module.init_inverse(1 + self.alpha, -self.alpha)\n",
    "        with torch.no_grad():\n",
    "            z = tuple(torch.zeros(s, dtype=x.dtype, device=x.device)\n",
    "                      for s in self.linear_module.z_shape(x.shape[0]))\n",
    "            u = tuple(torch.zeros(s, dtype=x.dtype, device=x.device)\n",
    "                      for s in self.linear_module.z_shape(x.shape[0]))\n",
    "\n",
    "            n = len(z)\n",
    "            bias = self.linear_module.bias(x)\n",
    "\n",
    "            err = 1.0\n",
    "            it = 0\n",
    "            errs = []\n",
    "            while (err > self.tol and it < self.max_iter):\n",
    "                u_12 = tuple(2 * z[i] - u[i] for i in range(n))\n",
    "                z_12 = self.linear_module.inverse(*tuple(u_12[i] + self.alpha * bias[i] for i in range(n)))\n",
    "                u = tuple(2 * z_12[i] - u_12[i] for i in range(n))\n",
    "                zn = self.nonlin_module(*u)\n",
    "\n",
    "                if self.save_abs_err:\n",
    "                    fn = self.nonlin_module(*self.linear_module(x, *zn))\n",
    "                    err = sum((zn[i] - fn[i]).norm().item() / (zn[i].norm().item()) for i in range(n))\n",
    "                    errs.append(err)\n",
    "                else:\n",
    "                    err = sum((zn[i] - z[i]).norm().item() / (1e-6 + zn[i].norm().item()) for i in range(n))\n",
    "                z = zn\n",
    "                it = it + 1\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"Forward: \", it, err)\n",
    "\n",
    "        # Run the forward pass one more time, tracking gradients, then backward placeholder\n",
    "        zn = self.linear_module(x, *z)\n",
    "        zn = self.nonlin_module(*zn)\n",
    "\n",
    "        zn = self.Backward.apply(self, *zn)\n",
    "        self.stats.fwd_iters.update(it)\n",
    "        self.stats.fwd_time.update(time.time() - start)\n",
    "        self.errs = errs\n",
    "        return zn\n",
    "\n",
    "    class Backward(Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, splitter, *z):\n",
    "            ctx.splitter = splitter\n",
    "            ctx.save_for_backward(*z)\n",
    "            return z\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, *g):\n",
    "            start = time.time()\n",
    "            sp = ctx.splitter\n",
    "            n = len(g)\n",
    "            z = ctx.saved_tensors\n",
    "            j = sp.nonlin_module.derivative(*z)\n",
    "            I = [j[i] == 0 for i in range(n)]\n",
    "            d = [(1 - j[i]) / j[i] for i in range(n)]\n",
    "            v = tuple(j[i] * g[i] for i in range(n))\n",
    "\n",
    "            z = tuple(torch.zeros(s, dtype=g[0].dtype, device=g[0].device)\n",
    "                      for s in sp.linear_module.z_shape(g[0].shape[0]))\n",
    "            u = tuple(torch.zeros(s, dtype=g[0].dtype, device=g[0].device)\n",
    "                      for s in sp.linear_module.z_shape(g[0].shape[0]))\n",
    "\n",
    "            err = 1.0\n",
    "            errs=[]\n",
    "            it = 0\n",
    "            while (err >sp.tol and it < sp.max_iter):\n",
    "                u_12 = tuple(2 * z[i] - u[i] for i in range(n))\n",
    "                z_12 = sp.linear_module.inverse_transpose(*u_12)\n",
    "                u = tuple(2 * z_12[i] - u_12[i] for i in range(n))\n",
    "                zn = tuple((u[i] + sp.alpha * (1 + d[i]) * v[i]) / (1 + sp.alpha * d[i]) for i in range(n))\n",
    "                for i in range(n):\n",
    "                    zn[i][I[i]] = v[i][I[i]]\n",
    "\n",
    "                err = sum((zn[i] - z[i]).norm().item() / (1e-6 + zn[i].norm().item()) for i in range(n))\n",
    "                errs.append(err)\n",
    "                z = zn\n",
    "                it = it + 1\n",
    "\n",
    "            if sp.verbose:\n",
    "                print(\"Backward: \", it, err)\n",
    "\n",
    "            dg = sp.linear_module.multiply_transpose(*zn)\n",
    "            dg = tuple(g[i] + dg[i] for i in range(n))\n",
    "\n",
    "            sp.stats.bkwd_iters.update(it)\n",
    "            sp.stats.bkwd_time.update(time.time() - start)\n",
    "            sp.errs = errs\n",
    "            return (None,) + dg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SingleFC Net and Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_args(defaults, kwargs):\n",
    "    d = defaults.copy()\n",
    "    for k, v in kwargs.items():\n",
    "        d[k] = v\n",
    "    return d\n",
    "\n",
    "MON_DEFAULTS = {\n",
    "    'alpha': 1.0,\n",
    "    'tol': 1e-5,\n",
    "    'max_iter': 50\n",
    "}\n",
    "\n",
    "class SingleFcNet(nn.Module):\n",
    "\n",
    "    def __init__(self, splittingMethod, in_dim=13, intermediate_dim=100, out_dim=4, m=0.1, **kwargs):\n",
    "        super().__init__()\n",
    "        linear_module = MONSingleFc(in_dim, intermediate_dim, m=m)\n",
    "        nonlin_module = MONReLU()\n",
    "        self.mon = splittingMethod(linear_module, nonlin_module, **expand_args(MON_DEFAULTS, kwargs))\n",
    "        self.Wout = nn.Linear(intermediate_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        z = self.mon(x)\n",
    "        return self.Wout(z[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda(tensor):\n",
    "    if torch.cuda.is_available():\n",
    "        return tensor.cuda()\n",
    "    else:\n",
    "        return tensor\n",
    "def run_tune_alpha(model, x, max_alpha):\n",
    "    print(\"----tuning alpha----\")\n",
    "    print(\"current: \", model.mon.alpha)\n",
    "    orig_alpha  =  model.mon.alpha\n",
    "    model.mon.stats.reset()\n",
    "    model.mon.alpha = max_alpha\n",
    "    with torch.no_grad():\n",
    "        model(x)\n",
    "    iters = model.mon.stats.fwd_iters.val\n",
    "    model.mon.stats.reset()\n",
    "    iters_n = iters\n",
    "    print('alpha: {}\\t iters: {}'.format(model.mon.alpha, iters_n))\n",
    "    while model.mon.alpha > 1e-4 and iters_n <= iters:\n",
    "        model.mon.alpha = model.mon.alpha/2\n",
    "        with torch.no_grad():\n",
    "            model(x)\n",
    "        iters = iters_n\n",
    "        iters_n = model.mon.stats.fwd_iters.val\n",
    "        print('alpha: {}\\t iters: {}'.format(model.mon.alpha, iters_n))\n",
    "        model.mon.stats.reset()\n",
    "\n",
    "    if iters==model.mon.max_iter:\n",
    "        print(\"none converged, resetting to current\")\n",
    "        model.mon.alpha=orig_alpha\n",
    "    else:\n",
    "        model.mon.alpha = model.mon.alpha * 2\n",
    "        print(\"setting to: \", model.mon.alpha)\n",
    "    print(\"--------------\\n\")\n",
    "\n",
    "def train(trainLoader, testLoader, model, epochs=15, max_lr=1e-3,\n",
    "          print_freq=10, change_mo=True, model_path=None, lr_mode='step',\n",
    "          step=10,tune_alpha=False,max_alpha=1.):\n",
    "\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=max_lr)\n",
    "\n",
    "    if lr_mode == '1cycle':\n",
    "        lr_schedule = lambda t: np.interp([t],\n",
    "                                          [0, (epochs-5)//2, epochs-5, epochs],\n",
    "                                          [1e-3, max_lr, 1e-3, 1e-3])[0]\n",
    "    elif lr_mode == 'step':\n",
    "        lr_scheduler =optim.lr_scheduler.StepLR(optimizer, step, gamma=0.1, last_epoch=-1)\n",
    "    elif lr_mode != 'constant':\n",
    "        raise Exception('lr mode one of constant, step, 1cycle')\n",
    "\n",
    "    if change_mo:\n",
    "        max_mo = 0.85\n",
    "        momentum_schedule = lambda t: np.interp([t],\n",
    "                                                [0, (epochs - 5) // 2, epochs - 5, epochs],\n",
    "                                                [0.95, max_mo, 0.95, 0.95])[0]\n",
    "\n",
    "    model = cuda(model)\n",
    "\n",
    "    for epoch in range(1, 1 + epochs):\n",
    "        nProcessed = 0\n",
    "        nTrain = len(trainLoader.dataset)\n",
    "        model.train()\n",
    "        start = time.time()\n",
    "        for batch_idx, batch in enumerate(trainLoader):\n",
    "            if (batch_idx  == 30 or batch_idx == int(len(trainLoader)/2)) and tune_alpha:\n",
    "                run_tune_alpha(model, cuda(batch[0]), max_alpha)\n",
    "            if lr_mode == '1cycle':\n",
    "                lr = lr_schedule(epoch -  1 + batch_idx/ len(trainLoader))\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = lr\n",
    "            if change_mo:\n",
    "                beta1 = momentum_schedule(epoch - 1 + batch_idx / len(trainLoader))\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['betas'] = (beta1, optimizer.param_groups[0]['betas'][1])\n",
    "\n",
    "            data, target = cuda(batch[0]), cuda(batch[1])\n",
    "            # print(\"HEREEEEEEE2\")\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(data)\n",
    "            # print(data.shape)\n",
    "            # print(preds.shape)\n",
    "            # print(target.shape)\n",
    "            ce_loss = nn.MSELoss()(preds, target)\n",
    "            ce_loss.backward()\n",
    "            nProcessed += len(data)\n",
    "            if batch_idx % print_freq == 0 and batch_idx > 0:\n",
    "            #     incorrect = preds.float().argmax(1).ne(target.data).sum()\n",
    "            #     err = 100. * incorrect.float() / float(len(data))\n",
    "                partialEpoch = epoch + batch_idx / len(trainLoader) - 1\n",
    "                print('Train Epoch: {:.2f} [{}/{} ({:.0f}%)]\\tLoss: {:.4f}'.format(\n",
    "                    partialEpoch, nProcessed, nTrain,\n",
    "                    100. * batch_idx / len(trainLoader),\n",
    "                    ce_loss.item()))\n",
    "                model.mon.stats.report()\n",
    "                model.mon.stats.reset()\n",
    "            optimizer.step()\n",
    "\n",
    "        if lr_mode == 'step':\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        if model_path is not None:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        print(\"Tot train time: {}\".format(time.time() - start))\n",
    "\n",
    "        start = time.time()\n",
    "        test_loss = 0\n",
    "        incorrect = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in testLoader:\n",
    "                data, target = cuda(batch[0]), cuda(batch[1])\n",
    "                preds = model(data)\n",
    "                ce_loss = nn.MSELoss(reduction='sum')(preds, target)\n",
    "                test_loss += ce_loss\n",
    "                # incorrect += preds.float().argmax(1).ne(target.data).sum()\n",
    "            test_loss /= len(testLoader.dataset)\n",
    "            # nTotal = len(testLoader.dataset)\n",
    "            # err = 100. * incorrect.float() / float(nTotal)\n",
    "            print('\\n\\nTest set: Test loss: {:.4f}'.format(\n",
    "                test_loss))\n",
    "\n",
    "        print(\"Tot test time: {}\\n\\n\\n\\n\".format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SingleFcNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/factslabegmc/mpc_ws/src/acados_mpc/acados_mpc/clean_monotone_INN_traintestsave/monotone_op_DEQ.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/factslabegmc/mpc_ws/src/acados_mpc/acados_mpc/clean_monotone_INN_traintestsave/monotone_op_DEQ.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_DEQ \u001b[39m=\u001b[39m SingleFcNet(MONPeacemanRachford,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/factslabegmc/mpc_ws/src/acados_mpc/acados_mpc/clean_monotone_INN_traintestsave/monotone_op_DEQ.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                         in_dim \u001b[39m=\u001b[39m \u001b[39m13\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/factslabegmc/mpc_ws/src/acados_mpc/acados_mpc/clean_monotone_INN_traintestsave/monotone_op_DEQ.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                         out_dim \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/factslabegmc/mpc_ws/src/acados_mpc/acados_mpc/clean_monotone_INN_traintestsave/monotone_op_DEQ.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                         alpha\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/factslabegmc/mpc_ws/src/acados_mpc/acados_mpc/clean_monotone_INN_traintestsave/monotone_op_DEQ.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                         max_iter\u001b[39m=\u001b[39m\u001b[39m300\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/factslabegmc/mpc_ws/src/acados_mpc/acados_mpc/clean_monotone_INN_traintestsave/monotone_op_DEQ.ipynb#X30sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                         tol\u001b[39m=\u001b[39m\u001b[39m1e-2\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/factslabegmc/mpc_ws/src/acados_mpc/acados_mpc/clean_monotone_INN_traintestsave/monotone_op_DEQ.ipynb#X30sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                         m\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SingleFcNet' is not defined"
     ]
    }
   ],
   "source": [
    "model_DEQ = SingleFcNet(MONPeacemanRachford,\n",
    "                        in_dim = 13,\n",
    "                        out_dim = 4,\n",
    "                        alpha=1.0,\n",
    "                        max_iter=300,\n",
    "                        tol=1e-2,\n",
    "                        m=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train It!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----tuning alpha----\n",
      "current:  1.0\n",
      "alpha: 1.0\t iters: 7\n",
      "alpha: 0.5\t iters: 6\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 0.32 [12928/40000 (32%)]\tLoss: 0.1505\n",
      "Fwd iters: 6.00\tFwd Time: 0.0021\tBkwd Iters: 6.00\tBkwd Time: 0.0033\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 7\n",
      "alpha: 0.5\t iters: 6\n",
      "alpha: 0.25\t iters: 8\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 0.64 [25728/40000 (64%)]\tLoss: 0.0541\n",
      "Fwd iters: 6.00\tFwd Time: 0.0021\tBkwd Iters: 6.00\tBkwd Time: 0.0032\n",
      "\n",
      "Train Epoch: 0.96 [38528/40000 (96%)]\tLoss: 0.0240\n",
      "Fwd iters: 6.00\tFwd Time: 0.0021\tBkwd Iters: 6.18\tBkwd Time: 0.0034\n",
      "\n",
      "Tot train time: 3.328490972518921\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0903\n",
      "Tot test time: 0.2564117908477783\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 8\n",
      "alpha: 0.5\t iters: 6\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 1.32 [12928/40000 (32%)]\tLoss: 0.0124\n",
      "Fwd iters: 6.00\tFwd Time: 0.0021\tBkwd Iters: 7.00\tBkwd Time: 0.0036\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 8\n",
      "alpha: 0.5\t iters: 6\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 1.64 [25728/40000 (64%)]\tLoss: 0.0108\n",
      "Fwd iters: 6.00\tFwd Time: 0.0022\tBkwd Iters: 7.00\tBkwd Time: 0.0036\n",
      "\n",
      "Train Epoch: 1.96 [38528/40000 (96%)]\tLoss: 0.0082\n",
      "Fwd iters: 6.00\tFwd Time: 0.0022\tBkwd Iters: 7.00\tBkwd Time: 0.0036\n",
      "\n",
      "Tot train time: 3.4047858715057373\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0290\n",
      "Tot test time: 0.43277740478515625\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 8\n",
      "alpha: 0.5\t iters: 6\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 2.32 [12928/40000 (32%)]\tLoss: 0.0060\n",
      "Fwd iters: 6.00\tFwd Time: 0.0020\tBkwd Iters: 7.00\tBkwd Time: 0.0035\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 8\n",
      "alpha: 0.5\t iters: 6\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 2.64 [25728/40000 (64%)]\tLoss: 0.0074\n",
      "Fwd iters: 6.00\tFwd Time: 0.0021\tBkwd Iters: 7.00\tBkwd Time: 0.0034\n",
      "\n",
      "Train Epoch: 2.96 [38528/40000 (96%)]\tLoss: 0.0037\n",
      "Fwd iters: 6.00\tFwd Time: 0.0021\tBkwd Iters: 7.00\tBkwd Time: 0.0035\n",
      "\n",
      "Tot train time: 3.3894596099853516\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0174\n",
      "Tot test time: 0.37635207176208496\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 8\n",
      "alpha: 0.5\t iters: 6\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 3.32 [12928/40000 (32%)]\tLoss: 0.0044\n",
      "Fwd iters: 6.00\tFwd Time: 0.0021\tBkwd Iters: 7.00\tBkwd Time: 0.0035\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 8\n",
      "alpha: 0.5\t iters: 6\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 3.64 [25728/40000 (64%)]\tLoss: 0.0036\n",
      "Fwd iters: 6.00\tFwd Time: 0.0021\tBkwd Iters: 7.00\tBkwd Time: 0.0036\n",
      "\n",
      "Train Epoch: 3.96 [38528/40000 (96%)]\tLoss: 0.0032\n",
      "Fwd iters: 6.00\tFwd Time: 0.0021\tBkwd Iters: 7.00\tBkwd Time: 0.0035\n",
      "\n",
      "Tot train time: 3.4275293350219727\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0144\n",
      "Tot test time: 0.42081189155578613\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 8\n",
      "alpha: 0.5\t iters: 6\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 4.32 [12928/40000 (32%)]\tLoss: 0.0023\n",
      "Fwd iters: 6.00\tFwd Time: 0.0021\tBkwd Iters: 7.00\tBkwd Time: 0.0036\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 8\n",
      "alpha: 0.5\t iters: 6\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 4.64 [25728/40000 (64%)]\tLoss: 0.0032\n",
      "Fwd iters: 6.00\tFwd Time: 0.0020\tBkwd Iters: 7.07\tBkwd Time: 0.0035\n",
      "\n",
      "Train Epoch: 4.96 [38528/40000 (96%)]\tLoss: 0.0033\n",
      "Fwd iters: 6.00\tFwd Time: 0.0021\tBkwd Iters: 7.00\tBkwd Time: 0.0036\n",
      "\n",
      "Tot train time: 3.4339711666107178\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0096\n",
      "Tot test time: 0.43339085578918457\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 8\n",
      "alpha: 0.5\t iters: 6\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 5.32 [12928/40000 (32%)]\tLoss: 0.0025\n",
      "Fwd iters: 6.00\tFwd Time: 0.0021\tBkwd Iters: 7.01\tBkwd Time: 0.0035\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 6\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 5.64 [25728/40000 (64%)]\tLoss: 0.0036\n",
      "Fwd iters: 6.00\tFwd Time: 0.0022\tBkwd Iters: 7.09\tBkwd Time: 0.0036\n",
      "\n",
      "Train Epoch: 5.96 [38528/40000 (96%)]\tLoss: 0.0022\n",
      "Fwd iters: 6.00\tFwd Time: 0.0020\tBkwd Iters: 7.08\tBkwd Time: 0.0035\n",
      "\n",
      "Tot train time: 3.42033052444458\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0148\n",
      "Tot test time: 0.43657755851745605\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 6\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 6.32 [12928/40000 (32%)]\tLoss: 0.0016\n",
      "Fwd iters: 6.00\tFwd Time: 0.0021\tBkwd Iters: 7.13\tBkwd Time: 0.0035\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 6\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 6.64 [25728/40000 (64%)]\tLoss: 0.0074\n",
      "Fwd iters: 6.13\tFwd Time: 0.0020\tBkwd Iters: 7.07\tBkwd Time: 0.0034\n",
      "\n",
      "Train Epoch: 6.96 [38528/40000 (96%)]\tLoss: 0.0022\n",
      "Fwd iters: 6.56\tFwd Time: 0.0022\tBkwd Iters: 7.07\tBkwd Time: 0.0036\n",
      "\n",
      "Tot train time: 3.4398727416992188\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0111\n",
      "Tot test time: 0.437603235244751\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 8\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 7.32 [12928/40000 (32%)]\tLoss: 0.0023\n",
      "Fwd iters: 6.96\tFwd Time: 0.0022\tBkwd Iters: 7.24\tBkwd Time: 0.0036\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 7.64 [25728/40000 (64%)]\tLoss: 0.0028\n",
      "Fwd iters: 6.98\tFwd Time: 0.0023\tBkwd Iters: 7.60\tBkwd Time: 0.0039\n",
      "\n",
      "Train Epoch: 7.96 [38528/40000 (96%)]\tLoss: 0.0015\n",
      "Fwd iters: 7.00\tFwd Time: 0.0023\tBkwd Iters: 7.48\tBkwd Time: 0.0037\n",
      "\n",
      "Tot train time: 3.4979631900787354\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0070\n",
      "Tot test time: 0.4514579772949219\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 8.32 [12928/40000 (32%)]\tLoss: 0.0016\n",
      "Fwd iters: 7.00\tFwd Time: 0.0023\tBkwd Iters: 7.58\tBkwd Time: 0.0038\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 8.64 [25728/40000 (64%)]\tLoss: 0.0016\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 7.76\tBkwd Time: 0.0037\n",
      "\n",
      "Train Epoch: 8.96 [38528/40000 (96%)]\tLoss: 0.0012\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 7.82\tBkwd Time: 0.0039\n",
      "\n",
      "Tot train time: 3.503889322280884\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0065\n",
      "Tot test time: 0.4450399875640869\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 9.32 [12928/40000 (32%)]\tLoss: 0.0015\n",
      "Fwd iters: 7.00\tFwd Time: 0.0023\tBkwd Iters: 7.87\tBkwd Time: 0.0039\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 9.64 [25728/40000 (64%)]\tLoss: 0.0013\n",
      "Fwd iters: 7.00\tFwd Time: 0.0023\tBkwd Iters: 7.80\tBkwd Time: 0.0039\n",
      "\n",
      "Train Epoch: 9.96 [38528/40000 (96%)]\tLoss: 0.0013\n",
      "Fwd iters: 7.00\tFwd Time: 0.0023\tBkwd Iters: 7.65\tBkwd Time: 0.0038\n",
      "\n",
      "Tot train time: 3.592303514480591\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0072\n",
      "Tot test time: 0.4452071189880371\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 10.32 [12928/40000 (32%)]\tLoss: 0.0008\n",
      "Fwd iters: 7.00\tFwd Time: 0.0023\tBkwd Iters: 7.97\tBkwd Time: 0.0039\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 10.64 [25728/40000 (64%)]\tLoss: 0.0009\n",
      "Fwd iters: 7.00\tFwd Time: 0.0023\tBkwd Iters: 7.89\tBkwd Time: 0.0040\n",
      "\n",
      "Train Epoch: 10.96 [38528/40000 (96%)]\tLoss: 0.0009\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "Tot train time: 3.5932657718658447\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0038\n",
      "Tot test time: 0.43650126457214355\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 11.32 [12928/40000 (32%)]\tLoss: 0.0013\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 7.99\tBkwd Time: 0.0039\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 8\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 11.64 [25728/40000 (64%)]\tLoss: 0.0009\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0038\n",
      "\n",
      "Train Epoch: 11.96 [38528/40000 (96%)]\tLoss: 0.0009\n",
      "Fwd iters: 7.00\tFwd Time: 0.0023\tBkwd Iters: 7.97\tBkwd Time: 0.0039\n",
      "\n",
      "Tot train time: 3.5443296432495117\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0038\n",
      "Tot test time: 0.43999481201171875\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 12.32 [12928/40000 (32%)]\tLoss: 0.0008\n",
      "Fwd iters: 7.00\tFwd Time: 0.0023\tBkwd Iters: 7.99\tBkwd Time: 0.0039\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 12.64 [25728/40000 (64%)]\tLoss: 0.0011\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "Train Epoch: 12.96 [38528/40000 (96%)]\tLoss: 0.0010\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 7.98\tBkwd Time: 0.0039\n",
      "\n",
      "Tot train time: 3.5377707481384277\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0037\n",
      "Tot test time: 0.4317913055419922\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 13.32 [12928/40000 (32%)]\tLoss: 0.0009\n",
      "Fwd iters: 7.00\tFwd Time: 0.0023\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 8\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 13.64 [25728/40000 (64%)]\tLoss: 0.0008\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0038\n",
      "\n",
      "Train Epoch: 13.96 [38528/40000 (96%)]\tLoss: 0.0010\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "Tot train time: 3.548497200012207\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0036\n",
      "Tot test time: 0.44238996505737305\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 14.32 [12928/40000 (32%)]\tLoss: 0.0011\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 8\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 14.64 [25728/40000 (64%)]\tLoss: 0.0008\n",
      "Fwd iters: 7.00\tFwd Time: 0.0023\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "Train Epoch: 14.96 [38528/40000 (96%)]\tLoss: 0.0009\n",
      "Fwd iters: 7.00\tFwd Time: 0.0021\tBkwd Iters: 7.98\tBkwd Time: 0.0035\n",
      "\n",
      "Tot train time: 3.4621574878692627\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0035\n",
      "Tot test time: 0.43981218338012695\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 8\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 15.32 [12928/40000 (32%)]\tLoss: 0.0008\n",
      "Fwd iters: 7.00\tFwd Time: 0.0024\tBkwd Iters: 7.99\tBkwd Time: 0.0039\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 15.64 [25728/40000 (64%)]\tLoss: 0.0008\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0040\n",
      "\n",
      "Train Epoch: 15.96 [38528/40000 (96%)]\tLoss: 0.0008\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "Tot train time: 3.6019444465637207\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0035\n",
      "Tot test time: 0.41200995445251465\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 16.32 [12928/40000 (32%)]\tLoss: 0.0009\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 7.97\tBkwd Time: 0.0038\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 16.64 [25728/40000 (64%)]\tLoss: 0.0011\n",
      "Fwd iters: 7.00\tFwd Time: 0.0023\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "Train Epoch: 16.96 [38528/40000 (96%)]\tLoss: 0.0008\n",
      "Fwd iters: 7.00\tFwd Time: 0.0023\tBkwd Iters: 8.00\tBkwd Time: 0.0040\n",
      "\n",
      "Tot train time: 3.615002155303955\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0034\n",
      "Tot test time: 0.45369625091552734\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 17.32 [12928/40000 (32%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0020\tBkwd Iters: 8.00\tBkwd Time: 0.0036\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 17.64 [25728/40000 (64%)]\tLoss: 0.0011\n",
      "Fwd iters: 7.00\tFwd Time: 0.0021\tBkwd Iters: 8.00\tBkwd Time: 0.0037\n",
      "\n",
      "Train Epoch: 17.96 [38528/40000 (96%)]\tLoss: 0.0009\n",
      "Fwd iters: 7.00\tFwd Time: 0.0020\tBkwd Iters: 7.99\tBkwd Time: 0.0036\n",
      "\n",
      "Tot train time: 3.3694264888763428\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0032\n",
      "Tot test time: 0.4132378101348877\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 18.32 [12928/40000 (32%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0020\tBkwd Iters: 7.99\tBkwd Time: 0.0035\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 18.64 [25728/40000 (64%)]\tLoss: 0.0008\n",
      "Fwd iters: 7.00\tFwd Time: 0.0021\tBkwd Iters: 8.00\tBkwd Time: 0.0038\n",
      "\n",
      "Train Epoch: 18.96 [38528/40000 (96%)]\tLoss: 0.0009\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 7.99\tBkwd Time: 0.0038\n",
      "\n",
      "Tot train time: 3.3319015502929688\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0033\n",
      "Tot test time: 0.390819787979126\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 19.32 [12928/40000 (32%)]\tLoss: 0.0006\n",
      "Fwd iters: 7.00\tFwd Time: 0.0021\tBkwd Iters: 8.00\tBkwd Time: 0.0036\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 19.64 [25728/40000 (64%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0038\n",
      "\n",
      "Train Epoch: 19.96 [38528/40000 (96%)]\tLoss: 0.0009\n",
      "Fwd iters: 7.00\tFwd Time: 0.0021\tBkwd Iters: 8.00\tBkwd Time: 0.0037\n",
      "\n",
      "Tot train time: 3.404282808303833\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0031\n",
      "Tot test time: 0.4429471492767334\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 20.32 [12928/40000 (32%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0023\tBkwd Iters: 7.99\tBkwd Time: 0.0039\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 20.64 [25728/40000 (64%)]\tLoss: 0.0009\n",
      "Fwd iters: 7.00\tFwd Time: 0.0021\tBkwd Iters: 7.98\tBkwd Time: 0.0038\n",
      "\n",
      "Train Epoch: 20.96 [38528/40000 (96%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0021\tBkwd Iters: 8.00\tBkwd Time: 0.0037\n",
      "\n",
      "Tot train time: 3.455662727355957\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0030\n",
      "Tot test time: 0.4440727233886719\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 21.32 [12928/40000 (32%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 21.64 [25728/40000 (64%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "Train Epoch: 21.96 [38528/40000 (96%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "Tot train time: 3.556408405303955\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0030\n",
      "Tot test time: 0.4402430057525635\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 22.32 [12928/40000 (32%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0021\tBkwd Iters: 8.00\tBkwd Time: 0.0037\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 22.64 [25728/40000 (64%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "Train Epoch: 22.96 [38528/40000 (96%)]\tLoss: 0.0008\n",
      "Fwd iters: 7.00\tFwd Time: 0.0023\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "Tot train time: 3.510105609893799\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0030\n",
      "Tot test time: 0.45703816413879395\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 23.32 [12928/40000 (32%)]\tLoss: 0.0010\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 23.64 [25728/40000 (64%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "Train Epoch: 23.96 [38528/40000 (96%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0038\n",
      "\n",
      "Tot train time: 3.541667938232422\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0029\n",
      "Tot test time: 0.4326469898223877\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 24.32 [12928/40000 (32%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0038\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 24.64 [25728/40000 (64%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0023\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "Train Epoch: 24.96 [38528/40000 (96%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "Tot train time: 3.5177042484283447\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0030\n",
      "Tot test time: 0.4410359859466553\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 25.32 [12928/40000 (32%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0038\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 25.64 [25728/40000 (64%)]\tLoss: 0.0005\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "Train Epoch: 25.96 [38528/40000 (96%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "Tot train time: 3.4814133644104004\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0029\n",
      "Tot test time: 0.43854355812072754\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 26.32 [12928/40000 (32%)]\tLoss: 0.0009\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 26.64 [25728/40000 (64%)]\tLoss: 0.0006\n",
      "Fwd iters: 7.00\tFwd Time: 0.0021\tBkwd Iters: 8.00\tBkwd Time: 0.0037\n",
      "\n",
      "Train Epoch: 26.96 [38528/40000 (96%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0038\n",
      "\n",
      "Tot train time: 3.4749927520751953\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0029\n",
      "Tot test time: 0.43935394287109375\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 27.32 [12928/40000 (32%)]\tLoss: 0.0006\n",
      "Fwd iters: 7.00\tFwd Time: 0.0021\tBkwd Iters: 8.00\tBkwd Time: 0.0038\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 27.64 [25728/40000 (64%)]\tLoss: 0.0008\n",
      "Fwd iters: 7.00\tFwd Time: 0.0012\tBkwd Iters: 8.00\tBkwd Time: 0.0020\n",
      "\n",
      "Train Epoch: 27.96 [38528/40000 (96%)]\tLoss: 0.0006\n",
      "Fwd iters: 7.00\tFwd Time: 0.0011\tBkwd Iters: 8.00\tBkwd Time: 0.0019\n",
      "\n",
      "Tot train time: 2.5523386001586914\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0029\n",
      "Tot test time: 0.18133115768432617\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 28.32 [12928/40000 (32%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0011\tBkwd Iters: 8.00\tBkwd Time: 0.0019\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 28.64 [25728/40000 (64%)]\tLoss: 0.0006\n",
      "Fwd iters: 7.00\tFwd Time: 0.0011\tBkwd Iters: 7.98\tBkwd Time: 0.0019\n",
      "\n",
      "Train Epoch: 28.96 [38528/40000 (96%)]\tLoss: 0.0008\n",
      "Fwd iters: 7.00\tFwd Time: 0.0011\tBkwd Iters: 8.00\tBkwd Time: 0.0019\n",
      "\n",
      "Tot train time: 1.591822862625122\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0029\n",
      "Tot test time: 0.17884445190429688\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 29.32 [12928/40000 (32%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0011\tBkwd Iters: 8.00\tBkwd Time: 0.0020\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 29.64 [25728/40000 (64%)]\tLoss: 0.0009\n",
      "Fwd iters: 7.00\tFwd Time: 0.0011\tBkwd Iters: 8.00\tBkwd Time: 0.0020\n",
      "\n",
      "Train Epoch: 29.96 [38528/40000 (96%)]\tLoss: 0.0008\n",
      "Fwd iters: 7.00\tFwd Time: 0.0018\tBkwd Iters: 8.00\tBkwd Time: 0.0032\n",
      "\n",
      "Tot train time: 2.015460968017578\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0029\n",
      "Tot test time: 0.2517421245574951\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 30.32 [12928/40000 (32%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0021\tBkwd Iters: 8.00\tBkwd Time: 0.0037\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 30.64 [25728/40000 (64%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0012\tBkwd Iters: 8.00\tBkwd Time: 0.0020\n",
      "\n",
      "Train Epoch: 30.96 [38528/40000 (96%)]\tLoss: 0.0006\n",
      "Fwd iters: 7.00\tFwd Time: 0.0021\tBkwd Iters: 8.00\tBkwd Time: 0.0036\n",
      "\n",
      "Tot train time: 2.8364527225494385\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0029\n",
      "Tot test time: 0.4374663829803467\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 31.32 [12928/40000 (32%)]\tLoss: 0.0009\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 31.64 [25728/40000 (64%)]\tLoss: 0.0010\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0038\n",
      "\n",
      "Train Epoch: 31.96 [38528/40000 (96%)]\tLoss: 0.0009\n",
      "Fwd iters: 7.00\tFwd Time: 0.0021\tBkwd Iters: 8.00\tBkwd Time: 0.0035\n",
      "\n",
      "Tot train time: 3.3652524948120117\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0029\n",
      "Tot test time: 0.25537776947021484\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 32.32 [12928/40000 (32%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 32.64 [25728/40000 (64%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "Train Epoch: 32.96 [38528/40000 (96%)]\tLoss: 0.0006\n",
      "Fwd iters: 7.00\tFwd Time: 0.0013\tBkwd Iters: 7.99\tBkwd Time: 0.0021\n",
      "\n",
      "Tot train time: 2.9463016986846924\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0029\n",
      "Tot test time: 0.20467925071716309\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 33.32 [12928/40000 (32%)]\tLoss: 0.0009\n",
      "Fwd iters: 7.00\tFwd Time: 0.0015\tBkwd Iters: 8.00\tBkwd Time: 0.0025\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 33.64 [25728/40000 (64%)]\tLoss: 0.0008\n",
      "Fwd iters: 7.00\tFwd Time: 0.0011\tBkwd Iters: 8.00\tBkwd Time: 0.0019\n",
      "\n",
      "Train Epoch: 33.96 [38528/40000 (96%)]\tLoss: 0.0006\n",
      "Fwd iters: 7.00\tFwd Time: 0.0011\tBkwd Iters: 8.00\tBkwd Time: 0.0019\n",
      "\n",
      "Tot train time: 1.892416000366211\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0029\n",
      "Tot test time: 0.17726349830627441\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 34.32 [12928/40000 (32%)]\tLoss: 0.0006\n",
      "Fwd iters: 7.00\tFwd Time: 0.0011\tBkwd Iters: 8.00\tBkwd Time: 0.0019\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 34.64 [25728/40000 (64%)]\tLoss: 0.0008\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "Train Epoch: 34.96 [38528/40000 (96%)]\tLoss: 0.0006\n",
      "Fwd iters: 7.00\tFwd Time: 0.0021\tBkwd Iters: 8.00\tBkwd Time: 0.0036\n",
      "\n",
      "Tot train time: 2.6792235374450684\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0029\n",
      "Tot test time: 0.16167187690734863\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 8\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 35.32 [12928/40000 (32%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0010\tBkwd Iters: 8.00\tBkwd Time: 0.0017\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 35.64 [25728/40000 (64%)]\tLoss: 0.0009\n",
      "Fwd iters: 7.00\tFwd Time: 0.0021\tBkwd Iters: 8.00\tBkwd Time: 0.0038\n",
      "\n",
      "Train Epoch: 35.96 [38528/40000 (96%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 7.99\tBkwd Time: 0.0038\n",
      "\n",
      "Tot train time: 2.4549472332000732\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0029\n",
      "Tot test time: 0.3297719955444336\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 36.32 [12928/40000 (32%)]\tLoss: 0.0008\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 36.64 [25728/40000 (64%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0021\tBkwd Iters: 8.00\tBkwd Time: 0.0037\n",
      "\n",
      "Train Epoch: 36.96 [38528/40000 (96%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0039\n",
      "\n",
      "Tot train time: 3.523610830307007\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0029\n",
      "Tot test time: 0.3563039302825928\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 8\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 37.32 [12928/40000 (32%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0011\tBkwd Iters: 8.00\tBkwd Time: 0.0018\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 8\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 37.64 [25728/40000 (64%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0011\tBkwd Iters: 8.00\tBkwd Time: 0.0019\n",
      "\n",
      "Train Epoch: 37.96 [38528/40000 (96%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0011\tBkwd Iters: 8.00\tBkwd Time: 0.0019\n",
      "\n",
      "Tot train time: 1.57547926902771\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0029\n",
      "Tot test time: 0.18703389167785645\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 38.32 [12928/40000 (32%)]\tLoss: 0.0008\n",
      "Fwd iters: 7.00\tFwd Time: 0.0012\tBkwd Iters: 8.00\tBkwd Time: 0.0020\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 38.64 [25728/40000 (64%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0011\tBkwd Iters: 8.00\tBkwd Time: 0.0019\n",
      "\n",
      "Train Epoch: 38.96 [38528/40000 (96%)]\tLoss: 0.0008\n",
      "Fwd iters: 7.00\tFwd Time: 0.0011\tBkwd Iters: 8.00\tBkwd Time: 0.0019\n",
      "\n",
      "Tot train time: 1.6130552291870117\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0029\n",
      "Tot test time: 0.18377971649169922\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 39.32 [12928/40000 (32%)]\tLoss: 0.0007\n",
      "Fwd iters: 7.00\tFwd Time: 0.0011\tBkwd Iters: 8.00\tBkwd Time: 0.0019\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 9\n",
      "alpha: 0.5\t iters: 7\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 39.64 [25728/40000 (64%)]\tLoss: 0.0006\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0038\n",
      "\n",
      "Train Epoch: 39.96 [38528/40000 (96%)]\tLoss: 0.0008\n",
      "Fwd iters: 7.00\tFwd Time: 0.0022\tBkwd Iters: 8.00\tBkwd Time: 0.0038\n",
      "\n",
      "Tot train time: 2.5363082885742188\n",
      "\n",
      "\n",
      "Test set: Test loss: 0.0029\n",
      "Tot test time: 0.362323522567749\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainLoader, testLoader = train_dataloader, test_dataloader\n",
    "\n",
    "train(trainLoader, testLoader,\n",
    "      model_DEQ,\n",
    "      max_lr=1e-3,\n",
    "      lr_mode='step',\n",
    "      step=10,\n",
    "      change_mo=False,\n",
    "      epochs=40,\n",
    "    #   epochs=1,\n",
    "      print_freq=100,\n",
    "      tune_alpha=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test It!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error pct: 0.1%\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "bad = 0\n",
    "num_trials = 1000\n",
    "for data in train_dataloader:\n",
    "    input_data, output_data = data\n",
    "    # print(input_data[0])\n",
    "    # print(output_data[0])\n",
    "    output_pred = model_DEQ(input_data)\n",
    "    # print(output_pred[0])\n",
    "    if ((output_pred[0] - output_data[0]) < torch.tensor([.08]*4)).all():\n",
    "        pass\n",
    "        # print(\"Good Prediction!\")\n",
    "    else:\n",
    "        bad +=1\n",
    "        # print(\"Bad Prediction\")\n",
    "\n",
    "    i += 1\n",
    "    if i >= 100:\n",
    "        print(f\"error pct: {(bad/num_trials)*100}%\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = \"DEQ_model50k.pt\"\n",
    "torch.save(model_DEQ.state_dict(), SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test A Pretrained INN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = SingleFcNet(MONPeacemanRachford,\n",
    "                        in_dim = 13,\n",
    "                        out_dim = 4,\n",
    "                        alpha=1.0,\n",
    "                        max_iter=300,\n",
    "                        tol=1e-2,\n",
    "                        m=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOAD_PATH = \"DEQModel_New.pt\"\n",
    "loaded_model.load_state_dict(torch.load(LOAD_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error pct: 0.8999999999999999%\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "bad = 0\n",
    "num_trials = 1000\n",
    "for data in train_dataloader:\n",
    "    input_data, output_data = data\n",
    "    # print(input_data[0])\n",
    "    # print(output_data[0])\n",
    "    output_pred = loaded_model(input_data)\n",
    "    # print(output_pred[0])\n",
    "    if ((output_pred[0] - output_data[0]) < torch.tensor([.08]*4)).all():\n",
    "        pass\n",
    "        # print(\"Good Prediction!\")\n",
    "    else:\n",
    "        bad +=1\n",
    "        # print(\"Bad Prediction\")\n",
    "\n",
    "    i += 1\n",
    "    if i >= 100:\n",
    "        print(f\"error pct: {(bad/num_trials)*100}%\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wardiNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
